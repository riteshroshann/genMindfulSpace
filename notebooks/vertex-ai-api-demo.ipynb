{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8819e476",
   "metadata": {},
   "source": [
    "# Google Cloud Vertex AI API for Mental Wellness Applications\n",
    "\n",
    "This notebook demonstrates how to use the Google Cloud Vertex AI API for machine learning pipelines, model deployment, and predictions specifically for mental health applications. We'll cover the complete workflow from authentication to model deployment and prediction serving.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Set up and authenticate with Google Cloud Vertex AI\n",
    "- Create and manage pipeline jobs for mental health data processing\n",
    "- Deploy models to endpoints for real-time predictions\n",
    "- Generate mental health support content using Gemini models\n",
    "- Monitor and manage ML resources effectively\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Google Cloud Project with Vertex AI API enabled\n",
    "- Service account credentials with appropriate permissions\n",
    "- Basic understanding of machine learning concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb10cdd2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup and Authentication\n",
    "\n",
    "First, let's install the required packages and set up authentication with Google Cloud credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31278e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install google-cloud-aiplatform google-cloud-storage google-auth --quiet\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# Google Cloud imports\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.auth import default\n",
    "from google.auth.exceptions import DefaultCredentialsError\n",
    "\n",
    "# Display the version to confirm installation\n",
    "print(f\"Google Cloud AI Platform SDK Version: {aiplatform.__version__}\")\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d564c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication and project configuration\n",
    "try:\n",
    "    # Try to get default credentials\n",
    "    credentials, project_id = default()\n",
    "    print(f\"‚úÖ Default credentials found!\")\n",
    "    print(f\"üìç Project ID: {project_id}\")\n",
    "except DefaultCredentialsError:\n",
    "    print(\"‚ùå No default credentials found.\")\n",
    "    print(\"Please set up authentication using one of these methods:\")\n",
    "    print(\"1. gcloud auth application-default login\")\n",
    "    print(\"2. Set GOOGLE_APPLICATION_CREDENTIALS environment variable\")\n",
    "    print(\"3. Use service account key file\")\n",
    "\n",
    "# Set your Google Cloud project configuration\n",
    "PROJECT_ID = project_id or \"your-project-id\"  # Replace with your actual project ID\n",
    "LOCATION = \"us-central1\"  # Region for Vertex AI\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-vertex-ai-pipelines\"  # For storing pipeline artifacts\n",
    "\n",
    "print(f\"\\nüîß Configuration:\")\n",
    "print(f\"   Project ID: {PROJECT_ID}\")\n",
    "print(f\"   Location: {LOCATION}\")\n",
    "print(f\"   Bucket: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba79632",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Vertex AI Client Initialization\n",
    "\n",
    "Now let's initialize the Vertex AI client and test basic connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI client\n",
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "print(\"üöÄ Vertex AI client initialized successfully!\")\n",
    "\n",
    "# Test basic connectivity by listing available models\n",
    "try:\n",
    "    # Initialize model registry client\n",
    "    model_client = aiplatform.gapic.ModelServiceClient()\n",
    "    \n",
    "    # List models in the project\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/{LOCATION}\"\n",
    "    models = model_client.list_models(parent=parent, page_size=5)\n",
    "    \n",
    "    print(f\"\\nüìã Available models in {PROJECT_ID}:\")\n",
    "    model_count = 0\n",
    "    for model in models:\n",
    "        print(f\"   ‚Ä¢ {model.display_name} (ID: {model.name.split('/')[-1]})\")\n",
    "        model_count += 1\n",
    "        if model_count >= 5:  # Limit output\n",
    "            break\n",
    "    \n",
    "    if model_count == 0:\n",
    "        print(\"   No custom models found (this is normal for new projects)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not list models: {e}\")\n",
    "    print(\"This is normal if you haven't deployed any custom models yet.\")\n",
    "\n",
    "print(\"\\n‚úÖ Client initialization and connectivity test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e104cbd",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Vertex AI Pipelines - Core Functionality\n",
    "\n",
    "This section demonstrates the pipeline capabilities that are central to Vertex AI's orchestration features. We'll create, submit, and monitor pipeline jobs for mental wellness data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99318367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's install the pipeline components package\n",
    "!pip install kfp google-cloud-pipeline-components --quiet\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import component, pipeline, Input, Output, Dataset, Model\n",
    "from google_cloud_pipeline_components.v1.custom_job import CustomTrainingJobOp\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(\"üì¶ Pipeline packages installed successfully!\")\n",
    "\n",
    "# Define a simple mental wellness data processing component\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn\", \"numpy\"]\n",
    ")\n",
    "def process_mood_data(\n",
    "    input_dataset: Input[Dataset],\n",
    "    processed_dataset: Output[Dataset],\n",
    "    mood_threshold: float = 0.5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Process mood tracking data for mental wellness analysis.\n",
    "    \n",
    "    Args:\n",
    "        input_dataset: Raw mood data\n",
    "        processed_dataset: Cleaned and processed data\n",
    "        mood_threshold: Threshold for mood classification\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with processing statistics\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Simulate mood data processing\n",
    "    print(f\"üîÑ Processing mood data with threshold: {mood_threshold}\")\n",
    "    \n",
    "    # Create sample processed data\n",
    "    processed_data = {\n",
    "        \"processed_records\": 1000,\n",
    "        \"mood_threshold\": mood_threshold,\n",
    "        \"positive_mood_ratio\": 0.65,\n",
    "        \"data_quality_score\": 0.92\n",
    "    }\n",
    "    \n",
    "    # Write processed data\n",
    "    output_path = Path(processed_dataset.path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(processed_data, f)\n",
    "    \n",
    "    print(f\"‚úÖ Data processed and saved to {processed_dataset.path}\")\n",
    "    return processed_data\n",
    "\n",
    "print(\"üß© Mental wellness data processing component defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9be7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sentiment analysis component for mental wellness\n",
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"transformers\", \"torch\", \"pandas\"]\n",
    ")\n",
    "def analyze_journal_sentiment(\n",
    "    processed_dataset: Input[Dataset],\n",
    "    sentiment_results: Output[Dataset],\n",
    "    model_name: str = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Analyze sentiment in journal entries for mental wellness insights.\n",
    "    \n",
    "    Args:\n",
    "        processed_dataset: Processed mood data\n",
    "        sentiment_results: Sentiment analysis results\n",
    "        model_name: HuggingFace model for sentiment analysis\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with sentiment statistics\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(f\"üß† Analyzing sentiment using model: {model_name}\")\n",
    "    \n",
    "    # Simulate sentiment analysis results\n",
    "    sentiment_data = {\n",
    "        \"total_entries\": 500,\n",
    "        \"positive_sentiment\": 320,\n",
    "        \"negative_sentiment\": 120,\n",
    "        \"neutral_sentiment\": 60,\n",
    "        \"average_sentiment_score\": 0.72,\n",
    "        \"model_used\": model_name,\n",
    "        \"analysis_timestamp\": \"2024-01-15T10:30:00Z\"\n",
    "    }\n",
    "    \n",
    "    # Write sentiment results\n",
    "    output_path = Path(sentiment_results.path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(sentiment_data, f)\n",
    "    \n",
    "    print(f\"‚úÖ Sentiment analysis complete: {sentiment_data['positive_sentiment']} positive, {sentiment_data['negative_sentiment']} negative entries\")\n",
    "    return sentiment_data\n",
    "\n",
    "print(\"üé≠ Sentiment analysis component defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec904968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define the complete mental wellness pipeline\n",
    "@pipeline(\n",
    "    name=\"mental-wellness-analysis-pipeline\",\n",
    "    description=\"A pipeline for processing and analyzing mental wellness data\",\n",
    "    pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_runs\"\n",
    ")\n",
    "def mental_wellness_pipeline(\n",
    "    mood_threshold: float = 0.5,\n",
    "    sentiment_model: str = \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    enable_crisis_detection: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete mental wellness data analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        mood_threshold: Threshold for mood classification\n",
    "        sentiment_model: Model name for sentiment analysis\n",
    "        enable_crisis_detection: Whether to enable crisis detection\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Process mood data\n",
    "    mood_processing_task = process_mood_data(\n",
    "        mood_threshold=mood_threshold\n",
    "    )\n",
    "    mood_processing_task.set_display_name(\"Process Mood Data\")\n",
    "    \n",
    "    # Step 2: Analyze sentiment in journal entries\n",
    "    sentiment_task = analyze_journal_sentiment(\n",
    "        processed_dataset=mood_processing_task.outputs[\"processed_dataset\"],\n",
    "        model_name=sentiment_model\n",
    "    )\n",
    "    sentiment_task.set_display_name(\"Analyze Journal Sentiment\")\n",
    "    sentiment_task.after(mood_processing_task)\n",
    "    \n",
    "    # Step 3: Crisis detection (conditional)\n",
    "    if enable_crisis_detection:\n",
    "        # This would be a more complex component in practice\n",
    "        print(\"üö® Crisis detection enabled in pipeline\")\n",
    "    \n",
    "    return {\n",
    "        \"mood_processing_output\": mood_processing_task.outputs[\"processed_dataset\"],\n",
    "        \"sentiment_analysis_output\": sentiment_task.outputs[\"sentiment_results\"]\n",
    "    }\n",
    "\n",
    "print(\"üèóÔ∏è Mental wellness analysis pipeline defined!\")\n",
    "print(f\"üìç Pipeline root: gs://{BUCKET_NAME}/pipeline_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a18b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and submit the pipeline\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_spec_path = \"mental-wellness-pipeline.json\"\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=mental_wellness_pipeline,\n",
    "    package_path=pipeline_spec_path\n",
    ")\n",
    "\n",
    "print(f\"üì¶ Pipeline compiled to: {pipeline_spec_path}\")\n",
    "\n",
    "# Create pipeline job\n",
    "try:\n",
    "    # Initialize pipeline job\n",
    "    job = aiplatform.PipelineJob(\n",
    "        display_name=\"mental-wellness-analysis-run\",\n",
    "        template_path=pipeline_spec_path,\n",
    "        pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_runs\",\n",
    "        parameter_values={\n",
    "            \"mood_threshold\": 0.6,\n",
    "            \"sentiment_model\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            \"enable_crisis_detection\": True\n",
    "        },\n",
    "        enable_caching=True\n",
    "    )\n",
    "    \n",
    "    print(\"üéØ Pipeline job created successfully!\")\n",
    "    print(f\"   Display Name: {job.display_name}\")\n",
    "    print(f\"   Pipeline Root: {job.pipeline_root}\")\n",
    "    print(f\"   Parameters: {job.parameter_values}\")\n",
    "    \n",
    "    # Note: Uncomment the next line to actually submit the job\n",
    "    # job.run(sync=False)\n",
    "    print(\"\\n‚ö†Ô∏è  Pipeline job created but not submitted.\")\n",
    "    print(\"   To submit, uncomment: job.run(sync=False)\")\n",
    "    print(\"   ‚ö° This will actually execute the pipeline in Google Cloud!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating pipeline job: {e}\")\n",
    "    print(\"This might be due to missing bucket or permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1bd6e",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Generative AI Models - Gemini Integration\n",
    "\n",
    "This section demonstrates how to use Vertex AI's Gemini models for mental wellness applications, including CBT-focused conversations and crisis detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413151fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini model for mental wellness conversations\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting, HarmCategory\n",
    "import vertexai\n",
    "\n",
    "# Initialize Vertex AI for generative models\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Configure safety settings for mental wellness context\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize Gemini model with CBT-focused configuration\n",
    "model = GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    safety_settings=safety_settings,\n",
    "    system_instruction=\"\"\"You are a compassionate mental wellness AI assistant trained in Cognitive Behavioral Therapy (CBT) techniques. \n",
    "\n",
    "Your role is to:\n",
    "- Provide supportive, empathetic responses\n",
    "- Help users identify thought patterns and cognitive distortions\n",
    "- Suggest evidence-based coping strategies\n",
    "- Encourage professional help when needed\n",
    "- Detect crisis situations and provide appropriate resources\n",
    "\n",
    "Guidelines:\n",
    "- Use warm, non-judgmental language\n",
    "- Focus on CBT principles like thought challenging and behavioral activation\n",
    "- Never provide medical diagnoses or replace professional therapy\n",
    "- If crisis indicators are detected, provide immediate support resources\n",
    "- Encourage mindfulness and self-compassion techniques\n",
    "\n",
    "Remember: You are here to support, not to replace professional mental health care.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"üß† Gemini model initialized with mental wellness configuration!\")\n",
    "print(\"üõ°Ô∏è Safety settings configured for therapeutic context\")\n",
    "print(\"üìã CBT-focused system instruction loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the mental wellness conversation system\n",
    "def test_mental_wellness_conversation():\n",
    "    \"\"\"Test various mental wellness conversation scenarios.\"\"\"\n",
    "    \n",
    "    test_scenarios = [\n",
    "        {\n",
    "            \"name\": \"Anxiety Support\",\n",
    "            \"message\": \"I've been feeling really anxious about work lately. My thoughts keep racing and I can't seem to calm down. What can I do?\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Mood Tracking\",\n",
    "            \"message\": \"I've been tracking my mood and notice I feel down every Monday. Is this normal?\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CBT Technique Request\",\n",
    "            \"message\": \"I keep thinking 'I'm a failure' when things don't go perfectly. Can you help me challenge this thought?\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Crisis Detection Test\",\n",
    "            \"message\": \"I'm feeling really overwhelmed and don't know if I can handle this anymore.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for scenario in test_scenarios:\n",
    "        print(f\"\\nüé≠ Scenario: {scenario['name']}\")\n",
    "        print(f\"üí¨ User: {scenario['message']}\")\n",
    "        print(\"ü§ñ AI Response:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Generate response using Gemini\n",
    "            response = model.generate_content(\n",
    "                scenario['message'],\n",
    "                generation_config={\n",
    "                    \"max_output_tokens\": 300,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"top_p\": 0.8,\n",
    "                    \"top_k\": 40\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            print(response.text)\n",
    "            \n",
    "            # Check for potential crisis indicators (simple keyword detection)\n",
    "            crisis_keywords = [\"overwhelmed\", \"can't handle\", \"hopeless\", \"end it all\", \"hurt myself\"]\n",
    "            if any(keyword in scenario['message'].lower() for keyword in crisis_keywords):\n",
    "                print(\"\\nüö® CRISIS DETECTION ALERT: This message contains potential crisis indicators.\")\n",
    "                print(\"   Appropriate crisis resources should be provided immediately.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating response: {e}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Run the conversation tests\n",
    "test_mental_wellness_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb1e3d4",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Model Deployment and Endpoints\n",
    "\n",
    "This section shows how to deploy models and create prediction endpoints for production mental wellness applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13535448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate endpoint creation and management\n",
    "from google.cloud.aiplatform import Endpoint, Model\n",
    "\n",
    "def demonstrate_endpoint_management():\n",
    "    \"\"\"\n",
    "    Demonstrate how to manage endpoints for mental wellness models.\n",
    "    Note: This is for demonstration - actual deployment requires trained models.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ Endpoint Management for Mental Wellness Models\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # List existing endpoints\n",
    "    try:\n",
    "        endpoints = Endpoint.list()\n",
    "        print(f\"üìã Found {len(endpoints)} existing endpoints:\")\n",
    "        \n",
    "        for i, endpoint in enumerate(endpoints[:3]):  # Limit to first 3\n",
    "            print(f\"   {i+1}. {endpoint.display_name}\")\n",
    "            print(f\"      ID: {endpoint.name.split('/')[-1]}\")\n",
    "            print(f\"      State: {endpoint.state if hasattr(endpoint, 'state') else 'Unknown'}\")\n",
    "            print()\n",
    "            \n",
    "        if len(endpoints) == 0:\n",
    "            print(\"   No endpoints found (this is normal for new projects)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not list endpoints: {e}\")\n",
    "    \n",
    "    print(\"\\nüîß Endpoint Creation Process:\")\n",
    "    print(\"1. Train a custom model (e.g., sentiment analysis for mental wellness)\")\n",
    "    print(\"2. Upload the model to Vertex AI Model Registry\")\n",
    "    print(\"3. Create an endpoint\")\n",
    "    print(\"4. Deploy the model to the endpoint\")\n",
    "    print(\"5. Configure traffic allocation and scaling\")\n",
    "    \n",
    "    # Example endpoint configuration for mental wellness\n",
    "    endpoint_config = {\n",
    "        \"display_name\": \"mental-wellness-sentiment-endpoint\",\n",
    "        \"description\": \"Endpoint for mental wellness sentiment analysis\",\n",
    "        \"labels\": {\n",
    "            \"application\": \"mental-wellness\",\n",
    "            \"model-type\": \"sentiment-analysis\",\n",
    "            \"environment\": \"production\"\n",
    "        },\n",
    "        \"network_config\": {\n",
    "            \"enable_private_service_connect\": False  # Set to True for private networks\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìù Example endpoint configuration:\")\n",
    "    for key, value in endpoint_config.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    \n",
    "    print(\"\\nüí° Best Practices for Mental Wellness Endpoints:\")\n",
    "    print(\"   ‚Ä¢ Use appropriate scaling settings for expected traffic\")\n",
    "    print(\"   ‚Ä¢ Implement health checks and monitoring\")\n",
    "    print(\"   ‚Ä¢ Configure proper security and access controls\")\n",
    "    print(\"   ‚Ä¢ Set up logging for model performance tracking\")\n",
    "    print(\"   ‚Ä¢ Implement A/B testing for model improvements\")\n",
    "\n",
    "# Run the endpoint demonstration\n",
    "demonstrate_endpoint_management()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee2075a",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Predictions and Real-time Inference\n",
    "\n",
    "This section demonstrates how to make predictions using deployed models and handle real-time inference for mental wellness applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce35c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate prediction patterns for mental wellness applications\n",
    "def demonstrate_prediction_patterns():\n",
    "    \"\"\"\n",
    "    Show different prediction patterns used in mental wellness applications.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÆ Prediction Patterns for Mental Wellness\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Simulate different types of predictions\n",
    "    prediction_examples = [\n",
    "        {\n",
    "            \"type\": \"Mood Classification\",\n",
    "            \"input\": \"I had a great day today! Spent time with friends and accomplished my goals.\",\n",
    "            \"expected_output\": {\n",
    "                \"mood\": \"positive\",\n",
    "                \"confidence\": 0.92,\n",
    "                \"emotional_indicators\": [\"accomplishment\", \"social_connection\", \"satisfaction\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Crisis Detection\",\n",
    "            \"input\": \"I feel like there's no point anymore. Everything is falling apart.\",\n",
    "            \"expected_output\": {\n",
    "                \"crisis_level\": \"high\",\n",
    "                \"confidence\": 0.87,\n",
    "                \"recommended_action\": \"immediate_intervention\",\n",
    "                \"keywords_detected\": [\"no point\", \"falling apart\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"CBT Technique Recommendation\",\n",
    "            \"input\": \"I keep thinking I'm going to fail my presentation tomorrow.\",\n",
    "            \"expected_output\": {\n",
    "                \"cognitive_distortion\": \"catastrophizing\",\n",
    "                \"recommended_technique\": \"thought_challenging\",\n",
    "                \"confidence\": 0.89,\n",
    "                \"alternative_thoughts\": [\n",
    "                    \"I have prepared well for this presentation\",\n",
    "                    \"Even if it doesn't go perfectly, it's not a failure\",\n",
    "                    \"I've successfully presented before\"\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Therapeutic Activity Suggestion\",\n",
    "            \"input\": \"I'm feeling anxious and restless today.\",\n",
    "            \"expected_output\": {\n",
    "                \"activity_type\": \"mindfulness\",\n",
    "                \"specific_activities\": [\"breathing_exercise\", \"progressive_muscle_relaxation\"],\n",
    "                \"duration\": \"10-15 minutes\",\n",
    "                \"confidence\": 0.84\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Process each prediction example\n",
    "    for i, example in enumerate(prediction_examples, 1):\n",
    "        print(f\"\\n{i}. {example['type']}\")\n",
    "        print(f\"   Input: \\\"{example['input']}\\\"\")\n",
    "        print(f\"   Expected Output:\")\n",
    "        \n",
    "        for key, value in example['expected_output'].items():\n",
    "            if isinstance(value, list):\n",
    "                print(f\"     {key}: {', '.join(map(str, value))}\")\n",
    "            else:\n",
    "                print(f\"     {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nüí° Key Considerations for Mental Wellness Predictions:\")\n",
    "    print(\"   ‚Ä¢ Always include confidence scores\")\n",
    "    print(\"   ‚Ä¢ Provide fallback recommendations for low-confidence predictions\")\n",
    "    print(\"   ‚Ä¢ Implement human-in-the-loop for high-risk scenarios\")\n",
    "    print(\"   ‚Ä¢ Log all predictions for model improvement\")\n",
    "    print(\"   ‚Ä¢ Ensure cultural sensitivity in recommendations\")\n",
    "    print(\"   ‚Ä¢ Maintain user privacy and data protection\")\n",
    "\n",
    "# Demonstrate batch prediction processing\n",
    "def simulate_batch_prediction():\n",
    "    \"\"\"\n",
    "    Simulate batch prediction processing for mental wellness data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä Batch Prediction Simulation\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Simulate batch data\n",
    "    batch_data = [\n",
    "        \"I'm excited about starting my new job next week!\",\n",
    "        \"Today was overwhelming, too many things to handle.\",\n",
    "        \"Feeling grateful for my supportive family.\",\n",
    "        \"Can't shake this feeling of sadness lately.\",\n",
    "        \"The meditation session really helped me focus.\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Processing batch of {len(batch_data)} entries...\")\n",
    "    \n",
    "    # Simulate processing time and results\n",
    "    import time\n",
    "    for i, text in enumerate(batch_data, 1):\n",
    "        time.sleep(0.1)  # Simulate processing time\n",
    "        print(f\"   {i}/5 - Processed: \\\"{text[:30]}...\\\"\")\n",
    "    \n",
    "    print(\"‚úÖ Batch processing complete!\")\n",
    "    print(f\"   Processed: {len(batch_data)} entries\")\n",
    "    print(f\"   Success rate: 100%\")\n",
    "    print(f\"   Average processing time: 50ms per entry\")\n",
    "\n",
    "# Run prediction demonstrations\n",
    "demonstrate_prediction_patterns()\n",
    "simulate_batch_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69698a98",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Resource Management and Monitoring\n",
    "\n",
    "This final section covers best practices for managing Vertex AI resources, monitoring costs, and maintaining production mental wellness applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource management and monitoring functions\n",
    "def demonstrate_resource_management():\n",
    "    \"\"\"\n",
    "    Show best practices for managing Vertex AI resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîß Vertex AI Resource Management\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Resource monitoring\n",
    "    print(\"üìä Resource Monitoring:\")\n",
    "    print(\"   ‚Ä¢ Pipeline Jobs: Track execution time, success rates, resource usage\")\n",
    "    print(\"   ‚Ä¢ Endpoints: Monitor prediction latency, error rates, throughput\")\n",
    "    print(\"   ‚Ä¢ Models: Track performance metrics, drift detection\")\n",
    "    print(\"   ‚Ä¢ Training Jobs: Monitor training progress, resource utilization\")\n",
    "    \n",
    "    print(f\"\\nüí∞ Cost Optimization:\")\n",
    "    print(\"   ‚Ä¢ Use appropriate machine types for workloads\")\n",
    "    print(\"   ‚Ä¢ Implement auto-scaling for endpoints\")\n",
    "    print(\"   ‚Ä¢ Schedule batch jobs during off-peak hours\")\n",
    "    print(\"   ‚Ä¢ Clean up unused resources regularly\")\n",
    "    print(\"   ‚Ä¢ Use preemptible instances for non-critical workloads\")\n",
    "    \n",
    "    print(f\"\\nüõ°Ô∏è Security Best Practices:\")\n",
    "    print(\"   ‚Ä¢ Use IAM roles for fine-grained access control\")\n",
    "    print(\"   ‚Ä¢ Enable VPC Service Controls for sensitive data\")\n",
    "    print(\"   ‚Ä¢ Implement data encryption at rest and in transit\")\n",
    "    print(\"   ‚Ä¢ Regular security audits and compliance checks\")\n",
    "    print(\"   ‚Ä¢ Monitor access logs and unusual activities\")\n",
    "    \n",
    "    # Demonstrate cleanup operations\n",
    "    print(f\"\\nüßπ Resource Cleanup Operations:\")\n",
    "    cleanup_checklist = [\n",
    "        \"Delete unused endpoints and models\",\n",
    "        \"Clean up old pipeline artifacts\",\n",
    "        \"Remove temporary storage buckets\",\n",
    "        \"Archive completed training jobs\",\n",
    "        \"Update resource labels for tracking\"\n",
    "    ]\n",
    "    \n",
    "    for i, item in enumerate(cleanup_checklist, 1):\n",
    "        print(f\"   {i}. {item}\")\n",
    "\n",
    "def show_monitoring_setup():\n",
    "    \"\"\"\n",
    "    Demonstrate monitoring setup for mental wellness applications.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìà Monitoring Setup for Mental Wellness Apps\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Key metrics to monitor\n",
    "    monitoring_metrics = {\n",
    "        \"Model Performance\": [\n",
    "            \"Prediction accuracy\",\n",
    "            \"Response time\",\n",
    "            \"Crisis detection rate\",\n",
    "            \"False positive/negative rates\"\n",
    "        ],\n",
    "        \"System Health\": [\n",
    "            \"API response times\",\n",
    "            \"Error rates\",\n",
    "            \"Throughput\",\n",
    "            \"Resource utilization\"\n",
    "        ],\n",
    "        \"User Experience\": [\n",
    "            \"Session duration\",\n",
    "            \"User satisfaction scores\",\n",
    "            \"Feature usage patterns\",\n",
    "            \"Dropout rates\"\n",
    "        ],\n",
    "        \"Business Impact\": [\n",
    "            \"User engagement metrics\",\n",
    "            \"Clinical outcome indicators\",\n",
    "            \"Cost per prediction\",\n",
    "            \"ROI on mental wellness interventions\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, metrics in monitoring_metrics.items():\n",
    "        print(f\"\\nüìä {category}:\")\n",
    "        for metric in metrics:\n",
    "            print(f\"   ‚Ä¢ {metric}\")\n",
    "    \n",
    "    print(f\"\\nüö® Alerting Configuration:\")\n",
    "    alert_conditions = [\n",
    "        \"High crisis detection rate (immediate escalation)\",\n",
    "        \"Model accuracy drops below threshold\",\n",
    "        \"API error rate exceeds 5%\",\n",
    "        \"Response time > 2 seconds\",\n",
    "        \"Unusual usage patterns detected\"\n",
    "    ]\n",
    "    \n",
    "    for condition in alert_conditions:\n",
    "        print(f\"   ‚ö†Ô∏è  {condition}\")\n",
    "\n",
    "# Run resource management demonstrations\n",
    "demonstrate_resource_management()\n",
    "show_monitoring_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc89fb8",
   "metadata": {},
   "source": [
    "## üéØ Summary and Next Steps\n",
    "\n",
    "This notebook has demonstrated the core Vertex AI API capabilities for mental wellness applications:\n",
    "\n",
    "### ‚úÖ What We Covered:\n",
    "1. **Setup & Authentication** - Google Cloud credentials and Vertex AI initialization\n",
    "2. **Client Initialization** - Basic connectivity and model listing\n",
    "3. **Pipelines** - Complete ML pipeline for mental wellness data processing (as requested)\n",
    "4. **Generative AI** - Gemini model integration with CBT-focused conversations\n",
    "5. **Model Deployment** - Endpoint management and deployment strategies  \n",
    "6. **Predictions** - Real-time inference patterns for mental health applications\n",
    "7. **Resource Management** - Monitoring, cost optimization, and security best practices\n",
    "\n",
    "### üöÄ Pipeline Highlights (Your Requested Focus):\n",
    "- **Mental Wellness Pipeline**: End-to-end data processing workflow\n",
    "- **Component Architecture**: Modular, reusable components for mood analysis and sentiment detection\n",
    "- **Pipeline Jobs**: Automated execution with parameter configuration\n",
    "- **Artifact Management**: Proper storage and versioning of pipeline outputs\n",
    "\n",
    "### üîë Key Takeaways for Production:\n",
    "- Use CBT-focused system instructions for therapeutic conversations\n",
    "- Implement comprehensive crisis detection and response workflows\n",
    "- Monitor model performance and user safety metrics continuously\n",
    "- Follow security best practices for sensitive mental health data\n",
    "- Leverage pipeline automation for scalable data processing\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- [Vertex AI Pipelines Documentation](https://cloud.google.com/vertex-ai/docs/pipelines)\n",
    "- [Responsible AI Practices](https://ai.google/responsibility/responsible-ai-practices/)\n",
    "- [Mental Health AI Guidelines](https://cloud.google.com/solutions/healthcare-life-sciences)\n",
    "\n",
    "### üéØ Recommended Next Steps:\n",
    "1. Set up your Google Cloud project and enable Vertex AI APIs\n",
    "2. Run this notebook in your environment with real credentials\n",
    "3. Customize the pipeline components for your specific mental wellness use case\n",
    "4. Implement proper monitoring and alerting for production deployment\n",
    "5. Consider additional safety measures and compliance requirements\n",
    "\n",
    "**Remember**: Always prioritize user safety and privacy when deploying mental wellness AI applications. Consider consulting with mental health professionals and ensuring compliance with relevant healthcare regulations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
